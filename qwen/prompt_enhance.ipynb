{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c16396",
   "metadata": {},
   "source": [
    "### Universal Recognition with Qwen2.5-VL\n",
    "\n",
    "This notebook demonstrates how to use Qwen2.5-VL for universal recognition. It takes an image and a query, and then uses the model to interpret the user's query on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869bab2a",
   "metadata": {},
   "source": [
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install qwen-vl-utils\n",
    "!pip install qwen_agent\n",
    "!pip install openai#### \\[Setup\\]\n",
    "\n",
    "Load plotting and inference util."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638e9082-c1ef-4efd-9a10-e35507e25363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:40:04.049566Z",
     "iopub.status.busy": "2025-01-29T12:40:04.049365Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-x9up0p8r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-x9up0p8r\n",
      "  Resolved https://github.com/huggingface/transformers to commit 41b9b92b52215bed472c9a534a06abbc3a9a95cd\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting filelock (from transformers==4.51.0.dev0)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers==4.51.0.dev0)\n",
      "  Using cached huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers==4.51.0.dev0)\n",
      "  Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from transformers==4.51.0.dev0) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.51.0.dev0)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.51.0.dev0)\n",
      "  Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers==4.51.0.dev0)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.51.0.dev0)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers==4.51.0.dev0)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.51.0.dev0)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers==4.51.0.dev0)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.51.0.dev0) (4.13.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers==4.51.0.dev0)\n",
      "  Downloading charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.51.0.dev0)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.51.0.dev0)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.51.0.dev0)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m250.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.51.0.dev0-py3-none-any.whl size=11129395 sha256=c5a67aa346c6456f3ab02cc1efd73d75b8170096b197dc0999b93f7a59cab49b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k0j54sq6/wheels/14/a0/7b/8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
      "Successfully built transformers\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.1 idna-3.10 numpy-2.0.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.0.dev0 urllib3-2.3.0\n",
      "Collecting qwen-vl-utils\n",
      "  Using cached qwen_vl_utils-0.0.10-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting av (from qwen-vl-utils)\n",
      "  Downloading av-14.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from qwen-vl-utils) (24.2)\n",
      "Collecting pillow (from qwen-vl-utils)\n",
      "  Downloading pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: requests in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from qwen-vl-utils) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from requests->qwen-vl-utils) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from requests->qwen-vl-utils) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from requests->qwen-vl-utils) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from requests->qwen-vl-utils) (2025.1.31)\n",
      "Using cached qwen_vl_utils-0.0.10-py3-none-any.whl (6.7 kB)\n",
      "Downloading av-14.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.0/39.0 MB\u001b[0m \u001b[31m194.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m152.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow, av, qwen-vl-utils\n",
      "Successfully installed av-14.2.0 pillow-11.1.0 qwen-vl-utils-0.0.10\n",
      "Collecting openai\n",
      "  Using cached openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.2-py3-none-any.whl.metadata (64 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from openai) (4.13.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/miniconda3/envs/prompt/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached openai-1.70.0-py3-none-any.whl (599 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
      "Using cached pydantic-2.11.2-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.9.0 openai-1.70.0 pydantic-2.11.2 pydantic-core-2.33.1 sniffio-1.3.1 typing-inspection-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install qwen-vl-utils\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9596c50d-80a8-433f-b846-1fbf61145ccc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-01-29T12:40:16.511701Z",
     "iopub.status.busy": "2025-01-29T12:40:16.510916Z",
     "iopub.status.idle": "2025-01-29T12:40:16.878038Z",
     "shell.execute_reply": "2025-01-29T12:40:16.877543Z",
     "shell.execute_reply.started": "2025-01-29T12:40:16.511678Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import base64\n",
    "\n",
    "sys_prompt = '''You are a prompt enhancer for image generation models like DALL·E or Midjourney.Given:An image.\n",
    "\n",
    "The original text prompt used to generate the image.\n",
    "\n",
    "Your task is to analyze the image and the original prompt, and then output a more detailed, vivid, and compositionally rich enhanced prompt that would recreate the image with higher fidelity, aesthetic quality, and visual richness. The enhanced prompt should:\n",
    "\n",
    "Include specific objects, styles, settings, lighting, mood, and artistic techniques observed in the image.\n",
    "\n",
    "Be clear, descriptive, and suitable for input into an AI image generator.\n",
    "\n",
    "Improve upon vague or minimal descriptions in the original prompt.\n",
    "\n",
    "Input:\n",
    "\n",
    "Image: [insert image]\n",
    "\n",
    "Original Prompt: '[insert original prompt here]'\n",
    "\n",
    "Output:\n",
    "\n",
    "Enhanced Prompt: '[Your improved prompt here]'\n",
    "'''\n",
    "\n",
    "# @title inference function\n",
    "def inference(image_path, prompt, sys_prompt=sys_prompt, max_new_tokens=4096, return_input=False):\n",
    "    image = Image.open(image_path)\n",
    "    image_local_path = \"file://\" + image_path\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"image\": image_local_path},\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    # print(\"text:\", text)\n",
    "    inputs = processor(text=[text], images=[image], padding=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to('cuda')\n",
    "\n",
    "    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    if return_input:\n",
    "        return output_text[0], inputs\n",
    "    else:\n",
    "        return output_text[0]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#  base 64 \n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e4cd8",
   "metadata": {},
   "source": [
    "Load model and processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e829b782-0be7-4bc6-a576-6b815323376e",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-01-29T12:40:18.337731Z",
     "iopub.status.busy": "2025-01-29T12:40:18.337470Z",
     "iopub.status.idle": "2025-01-29T12:40:47.760976Z",
     "shell.execute_reply": "2025-01-29T12:40:47.760220Z",
     "shell.execute_reply.started": "2025-01-29T12:40:18.337713Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7afdd1aff948978a767b62c1e988a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "model_path = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(model_path, torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\",device_map=\"auto\")\n",
    "processor = AutoProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47ad45",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1. Birds Recognition\n",
    "\n",
    "There are more than 10,000 bird species in the world, and many of them have only slight differences in appearance. This is a very challenging fine-grained recognition task.\n",
    "\n",
    "##### 1.1 Single image recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1935af5e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-01-29T12:41:18.150397Z",
     "iopub.status.busy": "2025-01-29T12:41:18.149631Z",
     "iopub.status.idle": "2025-01-29T12:41:19.978329Z",
     "shell.execute_reply": "2025-01-29T12:41:19.977054Z",
     "shell.execute_reply.started": "2025-01-29T12:41:18.150371Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(INPUT_CSV_PATH)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# ====== Slice for the desired number of rows ======\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m df_subset \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mhead(NUM_SAMPLES)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ====== Store successful rows and enhanced prompts ======\u001b[39;00m\n\u001b[1;32m     23\u001b[0m successful_rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# ====== CONFIGURATION ======\n",
    "INPUT_CSV_PATH = \"../datasets/900k-diffusion-prompts-dataset/diffusion_prompts.csv\"\n",
    "OUTPUT_CSV_PATH = \"../output/enhanced_prompts.csv\"\n",
    "NUM_SAMPLES = 100  # <--- Change this number to control how many rows are processed\n",
    "IMAGE_SAVE_DIR = \"../datasets/900k-diffusion-prompts-dataset/downloaded_images\"\n",
    "\n",
    "# ====== Ensure image directory exists ======\n",
    "os.makedirs(IMAGE_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ====== Load the CSV ======\n",
    "df = pd.read_csv(INPUT_CSV_PATH)\n",
    "\n",
    "# ====== Slice for the desired number of rows ======\n",
    "df_subset = df.head(NUM_SAMPLES)\n",
    "\n",
    "# ====== Store successful rows and enhanced prompts ======\n",
    "successful_rows = []\n",
    "enhanced_prompts = []\n",
    "\n",
    "# ====== Process each row ======\n",
    "for idx, row in df_subset.iterrows():\n",
    "    prompt = row['prompt']\n",
    "    image_url = row['url']\n",
    "    image_id = row['id']\n",
    "    \n",
    "    try:\n",
    "        # Download image\n",
    "        response = requests.get(image_url)\n",
    "        response.raise_for_status()  # ensure it's a valid response\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        image_path = os.path.join(IMAGE_SAVE_DIR, f\"{image_id}.png\")\n",
    "        image.save(image_path)\n",
    "\n",
    "        # Run inference\n",
    "        model_response = inference(image_path, prompt)\n",
    "        print(f\"model_response: {model_response}\")\n",
    "\n",
    "        # Extract enhanced prompt\n",
    "        if isinstance(model_response, str) and \"Enhanced Prompt:\" in model_response:\n",
    "            enhanced_prompt = model_response.split(\"Enhanced Prompt:\")[-1].strip().strip('\"')\n",
    "        else:\n",
    "            print(f\"Warning: No enhanced prompt in response for row {idx}\")\n",
    "            continue  # skip this row\n",
    "\n",
    "        # Save successful row and enhanced prompt\n",
    "        enhanced_prompts.append(enhanced_prompt)\n",
    "        successful_rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {idx}: {e}\")\n",
    "        continue  # skip this row\n",
    "\n",
    "# ====== Build final DataFrame and save ======\n",
    "final_df = pd.DataFrame(successful_rows)\n",
    "final_df['prompt'] = enhanced_prompts  # replace with enhanced prompts\n",
    "\n",
    "final_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "\n",
    "# ====== Summary ======\n",
    "print(f\"Intended to process {NUM_SAMPLES} rows.\")\n",
    "print(f\"Successfully processed and saved {len(final_df)} rows.\")\n",
    "print(f\"Enhanced CSV saved to {OUTPUT_CSV_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
